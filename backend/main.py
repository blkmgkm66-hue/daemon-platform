# Daemon Backend API (MVP)
# FastAPI-based backend for AI-driven automation platform

import os
from fastapi import FastAPI, HTTPException, status
from pydantic import BaseModel, Field
import uvicorn
import google.cloud.logging
import logging
import vertexai
from vertexai.generative_models import GenerativeModel
from google.cloud import secretmanager
from google.cloud import storage
from google.cloud import firestore

# --- Logging Setup ---
# Set up Google Cloud Logging if running in GCP, otherwise use basic logging
# This assumes the execution environment has the necessary credentials
try:
    client = google.cloud.logging.Client()
    # Attaches a Google Cloud Logging handler to the root logger
    client.setup_logging()
    logging.info("Google Cloud Logging enabled.")
except google.auth.exceptions.DefaultCredentialsError:
    logging.basicConfig(level=logging.INFO)
    logging.info("Default credentials not found. Using basic logging.")


# --- Configuration (can be moved to a config file later) ---
GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "your-gcp-project-id")  # Replace default or set env
GCS_BUCKET_NAME = os.environ.get("GCS_BUCKET_NAME", "your-daemon-code-bucket")  # Replace default or set env
SECRET_MANAGER_SLACK_SECRET_NAME = "daemon-mvp-slack-token"  # Name of the secret to store Slack token in Secret Manager
# Add other config like Pub/Sub topics later

# Initialize Vertex AI
try:
    vertexai.init(project=GCP_PROJECT_ID, location="us-central1")
    logging.info("Vertex AI initialized successfully.")
except Exception as e:
    logging.error(f"Failed to initialize Vertex AI: {e}")
    # Continue without Vertex AI - endpoints will handle gracefully


# --- Pydantic Models for Request/Response ---

class GenerateWorkflowRequest(BaseModel):
    prompt: str = Field(..., description="User's natural language prompt (hardcoded for MVP)")


class GenerateWorkflowResponse(BaseModel):
    generated_code: str = Field(..., description="The Python code generated by the AI")
    workflow_id: str = Field(..., description="A unique ID for this potential workflow")


class SaveCredentialRequest(BaseModel):
    credential_name: str = Field(default=SECRET_MANAGER_SLACK_SECRET_NAME, description="Name of the credential (e.g., Slack token name)")
    secret_value: str = Field(..., description="The actual secret token/key")


class SaveCredentialResponse(BaseModel):
    message: str = Field(default="Credential saved successfully.")
    secret_version_id: str  # Will hold the version ID from Secret Manager


class DeployWorkflowRequest(BaseModel):
    workflow_id: str = Field(..., description="The unique ID from the generation step")
    generated_code: str = Field(..., description="The Python code to deploy")


class DeployWorkflowResponse(BaseModel):
    message: str = Field(default="Workflow deployed successfully.")
    webhook_url: str = Field(..., description="The unique URL for the webhook trigger")


# --- FastAPI App Instance ---
app = FastAPI(
    title="Daemon Backend API (MVP)",
    description="Manages AI code generation, deployment, and credential storage for Daemon.",
    version="0.1.0"
)


# --- API Endpoints ---

@app.get("/health", status_code=status.HTTP_200_OK)
async def health_check():
    """Basic health check endpoint."""
    logging.info("Health check endpoint hit.")
    return {"status": "ok"}


@app.post("/generate-workflow", response_model=GenerateWorkflowResponse, status_code=status.HTTP_201_CREATED)
async def generate_workflow(request: GenerateWorkflowRequest):
    """
    (MVP Stub) Takes a prompt, calls AI (Gemini/Vertex AI) to generate Python code.
    """
    logging.info(f"Generate workflow request received with prompt: {request.prompt[:50]}...")
    

    try:        model = GenerativeModel("gemini-2.5-flash")
        # Initialize Gemini 1.5 Flash model        # Build the prompt with role and context
        system_prompt = (
            "You are an expert Python developer creating automation scripts for the Daemon platform. "
            "Your task is to generate clean, production-ready Python code based on the user's request. "
            "\n\nAvailable SDK functions you can use:"
            "\n- get_trigger_data(): Returns the data that triggered this workflow"
            "\n- get_secret(secret_name): Retrieves a secret from Secret Manager"
            "\n- post_slack_message(message): Posts a message to Slack"
            "\n\nGenerate ONLY the Python code without any markdown formatting or explanation."
        )
        
        full_prompt = f"{system_prompt}\n\nUser Request: {request.prompt}"
        
        # Generate code with low temperature for consistency
        response = model.generate_content(
            full_prompt,
            generation_config={
                "temperature": 0.1,
                "top_p": 0.95,
                "max_output_tokens": 2048,
            }
        )
        
        generated_code = response.text.strip()
        
        # Generate a simple workflow ID (in production, use UUID)
        import hashlib
        workflow_id = f"wf-{hashlib.md5(request.prompt.encode()).hexdigest()[:12]}"
        
        logging.info(f"Successfully generated workflow code for prompt: {request.prompt[:50]}...")
    except Exception as e:
        logging.error(f"Error generating workflow code: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to generate workflow: {str(e)}"
        )
    
    return GenerateWorkflowResponse(
        generated_code=generated_code,
        workflow_id=workflow_id
    )


@app.post("/save-credential", response_model=SaveCredentialResponse, status_code=status.HTTP_201_CREATED)
async def save_credential(request: SaveCredentialRequest):
    """
    (MVP Stub) Saves a credential (e.g., Slack token) to Secret Manager.
    """
    logging.info(f"Save credential request for: {request.credential_name}")
    
    # Initialize Secret Manager client
    sm_client = secretmanager.SecretManagerServiceClient()
    
    # Use fixed secret name for MVP
    secret_id = SECRET_MANAGER_SLACK_SECRET_NAME
    project_path = f"projects/{GCP_PROJECT_ID}"
    secret_path = f"{project_path}/secrets/{secret_id}"
    
    try:
        # Try to add a new version to existing secret
        payload_bytes = request.secret_value.encode('UTF-8')
        parent = secret_path
        payload = {'data': payload_bytes}
        
        response = sm_client.add_secret_version(
            request={"parent": parent, "payload": payload}
        )
        secret_version_id = response.name.split("/")[-1]
        
        logging.info(f"Added new version {secret_version_id} to secret {secret_id}")
        
    except Exception as e:
        # If secret doesn't exist (NotFound), create it first
        if "NOT_FOUND" in str(e) or "not found" in str(e).lower():
            logging.info(f"Secret {secret_id} not found, creating it...")
            
            try:
                # Create the secret
                secret = sm_client.create_secret(
                    request={
                        "parent": project_path,
                        "secret_id": secret_id,
                        "secret": {
                            "replication": {"automatic": {}},
                        },
                    }
                )
                logging.info(f"Created secret: {secret.name}")
                
                # Now add the first version
                payload_bytes = request.secret_value.encode('UTF-8')
                payload = {'data': payload_bytes}
                
                response = sm_client.add_secret_version(
                    request={"parent": secret.name, "payload": payload}
                )
                secret_version_id = response.name.split("/")[-1]
                
                logging.info(f"Added first version {secret_version_id} to new secret {secret_id}")
                
            except Exception as create_error:
                logging.error(f"Error creating secret: {create_error}")
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"Failed to create secret: {str(create_error)}"
                )
        else:
            # Some other error occurred
            logging.error(f"Error adding secret version: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Failed to save credential: {str(e)}"
            )    return SaveCredentialResponse(
        message="Credential saved successfully.",
        secret_version_id=secret_version_id
    )


@app.post("/deploy-workflow", response_model=DeployWorkflowResponse, status_code=status.HTTP_201_CREATED)
async def deploy_workflow(request: DeployWorkflowRequest):
    """
    (MVP Stub) Deploys generated code to Cloud Run/Functions and sets up webhook trigger.
    """
    logging.info(f"Deploy workflow request for workflow_id: {request.workflow_id}")
    
    try:
        # Initialize GCS client
        storage_client = storage.Client()
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        
        # Save generated code to GCS
        # Path format: gs://BUCKET_NAME/{workflow_id}/main.py
        code_path = f"{request.workflow_id}/main.py"
        blob = bucket.blob(code_path)
        blob.upload_from_string(request.generated_code, content_type='text/x-python')
        
        logging.info(f"Saved workflow code to gs://{GCS_BUCKET_NAME}/{code_path}")
        
        # Initialize Firestore client
        db = firestore.Client()
        
        # Construct API Gateway webhook URL (manually configured for MVP)
        # Format: https://your-api-gateway-url/invoke/{workflow_id}
        # TODO: Replace with actual API Gateway URL after manual setup
        webhook_url = f"https://daemon-webhook-placeholder-run.app/trigger/{request.workflow_id}"
        
        # Save workflow metadata to Firestore
        workflow_doc = db.collection('workflows').document(request.workflow_id)
        workflow_doc.set({
            'workflow_id': request.workflow_id,
            'code_path': f"gs://{GCS_BUCKET_NAME}/{code_path}",
            'webhook_url': webhook_url,
            'created_at': firestore.SERVER_TIMESTAMP,
            'status': 'deployed'
        })
        
        logging.info(f"Saved workflow metadata to Firestore for {request.workflow_id}")
        logging.info(f"Webhook URL: {webhook_url}")
        
    except Exception as e:
        logging.error(f"Error deploying workflow: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to deploy workflow: {str(e)}"
        )
    return DeployWorkflowResponse(
        message="Workflow deployed successfully.",
        webhook_url=webhook_url
    )


# --- Main Entry Point ---
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=int(os.environ.get("PORT", 8080)),
        reload=True  # Enable auto-reload for development
    )
